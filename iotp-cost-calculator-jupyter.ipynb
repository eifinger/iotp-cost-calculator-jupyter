{
    "metadata": {
        "kernelspec": {
            "language": "python", 
            "display_name": "Python 2 with Spark 2.0", 
            "name": "python2-spark20"
        }, 
        "language_info": {
            "version": "2.7.11", 
            "file_extension": ".py", 
            "mimetype": "text/x-python", 
            "name": "python", 
            "nbconvert_exporter": "python", 
            "pygments_lexer": "ipython2", 
            "codemirror_mode": {
                "version": 2, 
                "name": "ipython"
            }
        }
    }, 
    "cells": [
        {
            "metadata": {
                "collapsed": true
            }, 
            "cell_type": "markdown", 
            "source": "What I learned so far:\n- IOTP in Germany behaves strange. Throwing MQTT errno104 connection reset by peer. No other region does that\n- paho mqtt client allocated memory for each message ~~published~~ queued\n- ~~paho mqtt client has to be disconnected in order to free memory~~ a message has to actually leave the client to free up memory\n- sending too many messages(amount varies) in a short time ~~will~~ may cause the iotp to disconnect you\n- this may result in a client caught in some never ending loop\n- the topic is always part of the message. \n- #IOTP will count the bytes in the message not the payload"
        }, 
        {
            "metadata": {}, 
            "cell_type": "markdown", 
            "source": "## Dependencies"
        }, 
        {
            "execution_count": 2, 
            "cell_type": "code", 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Requirement already satisfied: cloudant in /gpfs/global_fs01/sym_shared/YPProdSpark/user/sadc-e801fc74509d99-7b222e72cfaf/.local/lib/python2.7/site-packages\nRequirement already satisfied: requests<3.0.0,>=2.7.0 in /usr/local/src/bluemix_jupyter_bundle.v59/notebook/lib/python2.7/site-packages (from cloudant)\n"
                }
            ], 
            "metadata": {}, 
            "source": "!pip install cloudant"
        }, 
        {
            "metadata": {}, 
            "cell_type": "markdown", 
            "source": "## Credentials"
        }, 
        {
            "execution_count": 3, 
            "cell_type": "code", 
            "outputs": [], 
            "metadata": {
                "collapsed": true
            }, 
            "source": "credentials = {\n  'username':'',\n  'password':\"\",\n  'host':'',\n  'port':'443',\n  'url':''\n}"
        }, 
        {
            "execution_count": 4, 
            "cell_type": "code", 
            "outputs": [], 
            "metadata": {
                "collapsed": true
            }, 
            "source": "# The code was removed by DSX for sharing."
        }, 
        {
            "metadata": {}, 
            "cell_type": "markdown", 
            "source": "## Util functions"
        }, 
        {
            "execution_count": 5, 
            "cell_type": "code", 
            "outputs": [], 
            "metadata": {
                "collapsed": true
            }, 
            "source": "from cloudant import Cloudant\ndef getDB():\n    database = \"iotp-cost-calculator\"\n    client = Cloudant(credentials['username'], credentials['password'], url=credentials['url'], connect=True)\n    return client[database]"
        }, 
        {
            "execution_count": 6, 
            "cell_type": "code", 
            "outputs": [], 
            "metadata": {
                "collapsed": true
            }, 
            "source": "import numpy\ndef removeOutliers(input):\n    median = numpy.median(numpy.array(input))\n    result = [s for s in input if s < 1.5*median and s > median/1.5]\n    return result"
        }, 
        {
            "metadata": {}, 
            "cell_type": "markdown", 
            "source": "## Number crunching"
        }, 
        {
            "metadata": {}, 
            "cell_type": "markdown", 
            "source": "### Static overhead calculation"
        }, 
        {
            "execution_count": 8, 
            "cell_type": "code", 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Qos: 0, actual size: 58\nCleaned Mean: 217.956264138%\nCalculated static overhead: 68.4146332\nQos: 1, actual size: 58\nCleaned Mean: 228.959875%\nCalculated static overhead: 74.7967275\nMean static overhead for actual_size 58: 71.60568035\n######################################################\nQos: 0, actual size: 113\nCleaned Mean: 162.281235398%\nCalculated static overhead: 70.377796\nQos: 1, actual size: 113\nCleaned Mean: 182.885357522%\nCalculated static overhead: 93.660454\nQos: 2, actual size: 113\nCleaned Mean: 211.21319823%\nCalculated static overhead: 125.670914\nMean static overhead for actual_size 113: 96.5697213333\n######################################################\nQos: 0, actual size: 527\nCleaned Mean: 113.177984364%\nCalculated static overhead: 69.4479776\nQos: 1, actual size: 527\nCleaned Mean: 114.678289374%\nCalculated static overhead: 77.354585\nQos: 2, actual size: 527\nCleaned Mean: 116.312523719%\nCalculated static overhead: 85.967\nMean static overhead for actual_size 527: 77.5898542\n######################################################\nQos: 0, actual size: 1058\nCleaned Mean: 106.564087713%\nCalculated static overhead: 69.448048\nQos: 1, actual size: 1058\nCleaned Mean: 107.446005198%\nCalculated static overhead: 78.778735\nQos: 2, actual size: 1058\nCleaned Mean: 109.450671078%\nCalculated static overhead: 99.9881\nMean static overhead for actual_size 1058: 82.7382943333\n######################################################\nQos: 0, actual size: 5323\nCleaned Mean: 101.322263457%\nCalculated static overhead: 70.3840838\nQos: 1, actual size: 5323\nCleaned Mean: 100.007964691%\nCalculated static overhead: 0.423960500001\nQos: 2, actual size: 5323\nCleaned Mean: 107.354040954%\nCalculated static overhead: 391.4556\nMean static overhead for actual_size 5323: 70.3840838\n######################################################\nOverall static overhead for qos 0: 69.61450772\nOverall static overhead for qos 1: 81.147625375\nOverall percentage mean for qos 1: 1.50030500949\nOverall static overhead for qos 2: 103.875338\nOverall percentage mean for qos 2: 4.58315842625\n"
                }
            ], 
            "metadata": {}, 
            "source": "import numpy as np\ndb = getDB()\ndocuments = db.get_view_result('_design/analysisEnriched', 'analysisEnriched',raw_result=True)['rows']\n\noverall_static_overhead_list = {}\noverall_static_overhead_list[0] = []\noverall_static_overhead_list[1] = []\noverall_static_overhead_list[2] = []\noverall_percentage_list = {}\noverall_percentage_list[1] = []\noverall_percentage_list[2] = []\n\nfor actual_size in [58,113,527,1058,5323]:\n    static_overhead_list = []\n    qos_zero_mean = 0\n    for qos in range(0,3):\n        if(actual_size == 58 and qos ==2): # Filter out this one -> useless data\n            continue\n        percentage_diff_list = []\n        for doc in documents:\n            #print(doc)\n            if doc['id'] != \"_design/analysisEnriched\" and doc['value']['qos'] == qos and doc['value']['actual_size'] == actual_size:\n                percentage_diff_list.append(doc['value']['percentage_diff'])\n        cleanedList = removeOutliers(percentage_diff_list)\n        mean = np.mean(cleanedList)\n        static_overhead = (actual_size*mean/100)-actual_size\n        static_overhead_list.append(static_overhead)\n        print(\"Qos: {}, actual size: {}\".format(qos,actual_size))\n        #print(\"Difference in data usages in percent:\")\n        #print(percentage_diff_list)\n        #print(\"Cleaned:\")\n        #print(cleanedList)\n        print(\"Cleaned Mean usage diff: {}%\".format(mean))\n        #print(\"Standard Deviation: {}\".format(np.std(cleanedList)))\n        print(\"Calculated static overhead: {}\".format(static_overhead))\n        overall_static_overhead_list[qos].append(static_overhead)\n        if qos == 0:\n            qos_zero_mean = mean\n        if qos > 0:\n            overall_percentage_list[qos].append(mean-qos_zero_mean)\n    cleaned_static_overhead_list = removeOutliers(static_overhead_list)\n    static_overhead_mean = np.mean(cleaned_static_overhead_list)\n    #print(static_overhead_list)\n    #print(cleaned_static_overhead_list)\n    print(\"Mean static overhead for actual_size {}: {}\".format(actual_size,static_overhead_mean))\n    print(\"######################################################\")\nfor qos in range(0,3):\n    cleaned_static_overhead_list = {}\n    cleaned_static_overhead_list[qos] = removeOutliers(overall_static_overhead_list[qos])\n    static_overhead_mean = np.mean(cleaned_static_overhead_list[qos])\n    print(\"Overall static overhead for qos {}: {}\".format(qos,static_overhead_mean))\n    \n    if qos > 0:\n        cleaned_percentage_list = {}\n        cleaned_percentage_list[qos] = removeOutliers(overall_percentage_list[qos])\n        percentage_mean = np.mean(cleaned_percentage_list[qos])\n        print(\"Overall percentage mean for qos {}: {}\".format(qos,percentage_mean))"
        }, 
        {
            "metadata": {}, 
            "cell_type": "markdown", 
            "source": "### Difference between qos data usage"
        }, 
        {
            "execution_count": 15, 
            "cell_type": "code", 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Qos: 0, overall reported: 154MB\nQos: 1, overall reported: 5312MB\nQos: 2, overall reported: 7581MB\nQos: 0, overall reported: 9072MB\nQos: 1, overall reported: 123646MB\nQos: 2, overall reported: 5168MB\nQos: 0, overall reported: 4809MB\nQos: 1, overall reported: 4243MB\nQos: 2, overall reported: 6521MB\nQos: 0, overall reported: 2607MB\nQos: 1, overall reported: 14747MB\nQos: 2, overall reported: 105791MB\nQos: 0, overall reported: 6746MB\nQos: 1, overall reported: 36771MB\nQos: 2, overall reported: 301MB\nactual_size: 58 qos_diff_1: 5157MB qos_diff_2: 7426MB\nactual_size: 113 qos_diff_1: 114573MB qos_diff_2: -3905MB\nactual_size: 527 qos_diff_1: -566MB qos_diff_2: 1711MB\nactual_size: 1058 qos_diff_1: 12139MB qos_diff_2: 103184MB\nactual_size: 5323 qos_diff_1: 30025MB qos_diff_2: -6445MB\n"
                }
            ], 
            "metadata": {}, 
            "source": "import numpy as np\ndb = getDB()\ndocuments = db.get_view_result('_design/analysisEnriched', 'analysisEnriched',raw_result=True)['rows']\n\noverall_reported_list = {}\noverall_reported_list[0] = []\noverall_reported_list[1] = []\noverall_reported_list[2] = []\nfor actual_size in [58,113,527,1058,5323]:\n    for qos in range(0,3):\n        reported_count = 0\n        for doc in documents:\n            #print(doc)\n            if doc['id'] != \"_design/analysisEnriched\" and doc['value']['qos'] == qos and doc['value']['actual_size'] == actual_size:\n                reported = doc['value']['reported_data_usage']\n                reported_count += reported\n        overall_reported_list[qos].append(reported_count)\n        print(\"Qos: {}, overall reported: {}MB\".format(qos,reported_count/1000000))\ni=0\nfor actual_size in [58,113,527,1058,5323]:\n    qos_diff_1 = overall_reported_list[1][i] - overall_reported_list[0][i]\n    qos_diff_2 = overall_reported_list[2][i] - overall_reported_list[0][i]\n    print(\"actual_size: {} qos_diff_1: {}MB qos_diff_2: {}MB\".format(actual_size,qos_diff_1/1000000,qos_diff_2/1000000))\n    i += 1"
        }, 
        {
            "metadata": {}, 
            "cell_type": "markdown", 
            "source": "## Visualization"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "outputs": [], 
            "metadata": {
                "collapsed": true
            }, 
            "source": "%matplotlib inline\nimport matplotlib.pyplot as plt\ndb = getDB()\n\nfor actual_size in [58,113,527,1058,5323]:\n    print(\"Actual size: {}\".format(actual_size))\n    for qos in range(0,3):\n        assumed_list = []\n        reported_list = []\n        timestamp_list = []\n        sending_time_list = []\n        data_usage_diff_list = []\n        time_took_list = []\n        percentage_diff_list = []\n        for doc in db:\n            #print(doc)\n            if doc['_id'] != \"_design/total_delta\" and doc['qos'] == qos and doc['actual_size'] == actual_size:\n                assumed_list.append(doc['assumed_delta_data_usage'])\n                reported_list.append(doc['delta_data_usage'])\n                data_usage_diff_list.append(doc['delta_data_usage'] - doc['assumed_delta_data_usage'])\n                timestamp_list.append(doc['storage_timestamp'])\n                time_took_list.append(doc['time_took'])\n                sending_time_list.append(doc['sending_time'])\n                percentage_diff_list.append(doc['delta_data_usage']*100.0 / (doc['assumed_delta_data_usage']*1.0))\n        assumed_plot = plt.scatter(sending_time_list,assumed_list,c=\"green\",label=\"assumed_delta_data_usage\")\n        reported_plot = plt.scatter(sending_time_list,reported_list,c=\"red\",label=\"reported_delta_data_usage\")\n        data_usage_diff_plot = plt.scatter(sending_time_list,data_usage_diff_list,c=\"blue\",label=\"data_usage_diff\")\n        plt.xlabel(\"sending_time\")\n        plt.ylabel(\"data_usage\")\n        plt.legend((assumed_plot,reported_plot,data_usage_diff_plot),(\"assumed_plot\",\"reported_plot\",\"data_usage_diff_plot\"),bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n        plt.xscale('log')\n        plt.yscale('log')\n        plt.show()\n        if len(data_usage_diff_list) > 0:    \n            mean_delta = sum(data_usage_diff_list)/len(data_usage_diff_list)\n        else:\n            mean_delta = 0\n        print(\"Qos: {}, actual size: {}\".format(qos,actual_size))\n        print(\"Mean delta: {}MB\".format(mean_delta/1000000.0))\n        print(\"Reported in MB:\")\n        print(map(lambda x: x/1000000.0,reported_list))\n        print(\"Assumed in MB:\")\n        print(map(lambda x: x/1000000.0,assumed_list))\n        print(\"Diff in MB:\")\n        print(map(lambda x: x/1000000.0,data_usage_diff_list))\n        print(\"Difference in data usages in percent:\")\n        print(percentage_diff_list)\n        print(\"Time took:\")\n        print(time_took_list)"
        }
    ], 
    "nbformat": 4, 
    "nbformat_minor": 1
}